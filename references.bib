@article{fluke2011,
   title={Astrophysical Supercomputing with GPUs: Critical Decisions for Early Adopters},
   volume={28},
   ISSN={1448-6083},
   url={http://dx.doi.org/10.1071/AS10019},
   DOI={10.1071/as10019},
   number={1},
   journal={Publications of the Astronomical Society of Australia},
   publisher={Cambridge University Press (CUP)},
   author={Fluke, Christopher J. and Barnes, David G. and Barsdell, Benjamin R. and Hassan, Amr H.},
   year={2011},
   pages={15–27} }

 @misc{webgpu-spec,
  author       = {{Khronos Group}},
  title        = {{WebGPU Specification}},
  year         = {2024},
  howpublished = {\url{https://www.w3.org/TR/webgpu/}},
  note         = {Accessed: 2026-01-25}
}

  
@article{zwart_high-performance_2007,
title = {High-performance direct gravitational N-body simulations on graphics processing units},
volume = {12},
issn = {1384-1076},
url = {https://www.sciencedirect.com/science/article/pii/S1384107607000504},
doi = {https://doi.org/10.1016/j.newast.2007.05.004},
abstract = {We present the results of gravitational direct N-body simulations using the commercial graphics processing units ({GPU}) {NVIDIA} Quadro {FX}1400 and {GeForce} 8800GTX, and compare the results with {GRAPE}-6Af special purpose hardware. The force evaluation of the N-body problem was implemented in Cg using the {GPU} directly to speed-up the calculations. The integration of the equations of motions were, running on the host computer, implemented in C using the 4th order predictor–corrector Hermite integrator with block time steps. We find that for a large number of particles (N≳104) modern graphics processing units offer an attractive low cost alternative to {GRAPE} special purpose hardware. A modern {GPU} continues to give a relatively flat scaling with the number of particles, comparable to that of the {GRAPE}. The {GRAPE} is designed to reach double precision, whereas the {GPU} is intrinsically single-precision. For relatively large time steps, the total energy of the N-body system was conserved better than to one in 106 on the {GPU}, which is impressive given the single-precision nature of the {GPU}. For the same time steps, the {GRAPE} gave somewhat more accurate results, by about an order of magnitude. However, smaller time steps allowed more energy accuracy on the grape, around 10−11, whereas for the {GPU} machine precision saturates around 10−6 For N≳106 the {GeForce} 8800GTX was about 20 times faster than the host computer. Though still about a factor of a few slower than {GRAPE}, modern {GPUs} outperform {GRAPE} in their low cost, long mean time between failure and the much larger onboard memory; the {GRAPE}-6Af holds at most 256k particles whereas the {GeForce} 8800GTX can hold 9 million particles in memory.},
pages = {641--650},
number = {8},
journaltitle = {New Astronomy},
author = {Zwart, Simon F. Portegies and Belleman, Robert G. and Geldof, Peter M.},
date = {2007},
keywords = {Gravitation, Methods: -body simulation, Methods: Numerical, Stellar dynamics},
}

@article{bedorf2010,
author = {Gaburov, Evghenii and Bédorf, Jeroen and Portegies Zwart, Simon},
year = {2010},
month = {05},
pages = {1119-1127},
title = {Gravitational tree-code on graphics processing units: Implementation in CUDA},
volume = {324},
journal = {Procedia Computer Science},
doi = {10.1016/j.procs.2010.04.124}
}

@article{fastnbody,
author = {Nyland, Lars and Harris, M. and Prins, Jan},
year = {2009},
month = {01},
pages = {677-695},
title = {Fast N-body simulation with CUDA},
journal = {GPU Gem, Vol. 3}
}
  
@article{skeletons_1994,
	title = {Skeletons from the Treecode Closet},
	volume = {111},
	issn = {0021-9991},
	url = {https://www.sciencedirect.com/science/article/pii/S0021999184710503},
	doi = {https://doi.org/10.1006/jcph.1994.1050},
	abstract = {We consider treecodes (N-body programs which use a tree data structure) from the standpoint of their worst-case behavior. That is, we derive upper bounds on the largest possible errors that are introduced into a calculation by use of various multipole acceptability criteria ({MAC}). We find that the conventional Barnes-Hut {MAC} can introduce potentially unbounded errors unless θ {\textless} 1/3, and that this behavior while rare, is demonstrable in astrophysically reasonable examples. We consider two other {MACs} closely related to the {BH} {MAC}. While they do not admit the same unbounded errors, they nevertheless require extraordinary amounts of {CPU} time to guarantee modest levels of accuracy. We derive new error bounds based on some additional, easily computed moments of the mass distribution. These error bounds form the basis for four new {MACs} which can be used to limit the absolute or relative error introduced by each multipole evaluation, or, with the introduction of some additional data structures, the absolute or rms error in the final acceleration of each particle. Using the Sum Squares {MAC} to analytically place a 1\% bound on the rms error in a series of test models, we find that it significantly outperforms the θ = 0.65 {BH} {MAC} in terms of both accuracy (mean, rms, and maximum error) and performance (floating point operation count).},
	pages = {136--155},
	number = {1},
	journaltitle = {Journal of Computational Physics},
	author = {Salmon, John K. and Warren, Michael S.},
	date = {1994},
}


  
@article{springel_2005,
	title = {The cosmological simulation code gadget-2},
	volume = {364},
	issn = {0035-8711},
	url = {https://doi.org/10.1111/j.1365-2966.2005.09655.x},
	doi = {10.1111/j.1365-2966.2005.09655.x},
	abstract = {We discuss the cosmological simulation code gadget-2, a new massively parallel {TreeSPH} code, capable of following a collisionless fluid with the N-body method, and an ideal gas by means of smoothed particle hydrodynamics ({SPH}). Our implementation of {SPH} manifestly conserves energy and entropy in regions free of dissipation, while allowing for fully adaptive smoothing lengths. Gravitational forces are computed with a hierarchical multipole expansion, which can optionally be applied in the form of a {TreePM} algorithm, where only short-range forces are computed with the ‘tree’ method while long-range forces are determined with Fourier techniques. Time integration is based on a quasi-symplectic scheme where long-range and short-range forces can be integrated with different time-steps. Individual and adaptive short-range time-steps may also be employed. The domain decomposition used in the parallelization algorithm is based on a space-filling curve, resulting in high flexibility and tree force errors that do not depend on the way the domains are cut. The code is efficient in terms of memory consumption and required communication bandwidth. It has been used to compute the first cosmological N-body simulation with more than 1010 dark matter particles, reaching a homogeneous spatial dynamic range of 105 per dimension in a three-dimensional box. It has also been used to carry out very large cosmological {SPH} simulations that account for radiative cooling and star formation, reaching total particle numbers of more than 250 million. We present the algorithms used by the code and discuss their accuracy and performance using a number of test problems. gadget-2 is publicly released to the research community.},
	pages = {1105--1134},
	number = {4},
	journaltitle = {Monthly Notices of the Royal Astronomical Society},
	author = {Springel, Volker},
	date = {2005-12},
	note = {\_eprint: https://academic.oup.com/mnras/article-pdf/364/4/1105/18657201/364-4-1105.pdf},
}

  

@article{barneshut,
	title = {A hierarchical O(N log N) force-calculation algorithm},
	volume = {324},
	issn = {1476-4687},
	url = {https://doi.org/10.1038/324446a0},
	doi = {10.1038/324446a0},
	abstract = {Until recently the gravitational N-body problem has been modelled numerically either by direct integration, in which the computation needed increases as N2, or by an iterative potential method in which the number of operations grows as N log N. Here we describe a novel method of directly calculating the force on N bodies that grows only as N log N. The technique uses a tree-structured hierarchical subdivision of space into cubic cells, each of which is recursively divided into eight subcells whenever more than one particle is found to occupy the same cell. This tree is constructed anew at every time step, avoiding ambiguity and tangling. Advantages over potential-solving codes are: accurate local interactions; freedom from geometrical assumptions and restrictions; and applicability to a wide class of systems, including (proto-)planetary, stellar, galactic and cosmological ones. Advantages over previous hierarchical tree-codes include simplicity and the possibility of rigorous analysis of error. Although we concentrate here on stellar dynamical applications, our techniques of efficiently handling a large number of long-range interactions and concentrating computational effort where most needed have potential applications in other areas of astrophysics as well.},
	number = {6096},
	journal = {Nature},
	author = {Barnes, Josh and Hut, Piet},
	month = dec,
	year = {1986},
	pages = {446--449},
}


  @inproceedings{realitycheck,
author = {Sengupta, Sthitadhi and Wu, Nan and Varvello, Matteo and Jana, Krish and Chen, Songqing and Han, Bo},
title = {From WebGL to WebGPU: A Reality Check of Browser-Based GPU Acceleration},
year = {2025},
isbn = {9798400718601},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3730567.3764504},
doi = {10.1145/3730567.3764504},
abstract = {With the rising demand for cost-effective and privacy-preserving deep learning and visualization services, service providers are increasingly turning to in-browser solutions. General-purpose computations, leveraging the graphics processing unit (GPU), are foundational to executing algorithms that power these services. Web graphics library (WebGL) is a widely adopted GPU-access application programming interface (API) designed for multidimensional rendering in browsers, while WebGPU is a newer API developed with compute-specific capabilities. Although WebGPU is a promising standard, its performance has not been systematically evaluated for general-purpose computation. This paper investigates WebGPU and WebGL for accelerating client-side computation in web browsers. By benchmarking key computational GPU kernels for 16 PolyBench and 2 CHStone functions, we measure the performance of WebGPU and WebGL across varying input sizes and algorithmic complexities. Our results show that: 1) both WebGPU and WebGL exhibit poorer performance than central processing unit (CPU)-based execution for small input data due to setup and CPU-GPU synchronization overheads, but they outperform CPU execution as the input data size increases; 2) WebGL performs better than WebGPU for small inputs, except for CPU-driven loop functions, due to its lower initial setup overhead; and 3) WebGPU outperforms WebGL for large inputs through optimized GPU thread utilization and achieves better performance for loop-driven algorithms across all input sizes by minimizing CPU-GPU data exchange. Overall, our results indicate that WebGPU is a competitive option for enhancing the execution performance of large-scale web applications.},
booktitle = {Proceedings of the 2025 ACM Internet Measurement Conference},
pages = {1018–1024},
numpages = {7},
keywords = {measurement, gpu acceleration, web performance, webgpu, webgl, webassembly},
location = {USA},
series = {IMC '25}
}

@article{usta_webgpu_2024,
	title = {{WEBGPU}: A {NEW} {GRAPHIC} {API} {FOR} 3D {WEBGIS} {APPLICATIONS}},
	volume = {{XLVIII}-4/W9-2024},
	url = {https://isprs-archives.copernicus.org/articles/XLVIII-4-W9-2024/377/2024/},
	doi = {10.5194/isprs-archives-XLVIII-4-W9-2024-377-2024},
	pages = {377--382},
	journaltitle = {The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
	author = {Usta, Z.},
	date = {2024},
}

@misc{webgpu-gpuweb,
  author       = {{GPU for the Web Working Group}},
  title        = {{WebGPU (GPU for the Web) Specification}},
  year         = {2026},
  note         = {Editor’s Draft},
  howpublished = {\url{https://gpuweb.github.io/gpuweb/}},
  urldate      = {2026-01-25}
}


  @misc{realtimeclothsimulation,
      title={Real-Time Cloth Simulation Using WebGPU: Evaluating Limits of High-Resolution}, 
      author={Nak-Jun Sung and Jun Ma and TaeHeon Kim and Yoo-joo Choi and Min-Hyung Choi and Min Hong},
      year={2025},
      eprint={2507.11794},
      archivePrefix={arXiv},
      primaryClass={cs.GR},
      url={https://arxiv.org/abs/2507.11794}, 
}

  @inproceedings{terascalewebviz,
author = {Congote, John and Segura, Alvaro and Kabongo, Luis and Moreno, Aitor and Posada, Jorge and Ruiz, Oscar},
title = {Interactive visualization of volumetric data with WebGL in real-time},
year = {2011},
isbn = {9781450307741},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2010425.2010449},
doi = {10.1145/2010425.2010449},
abstract = {This article presents and discusses the implementation of a direct volume rendering system for the Web, which articulates a large portion of the rendering task in the client machine. By placing the rendering emphasis in the local client, our system takes advantage of its power, while at the same time eliminates processing from unreliable bottlenecks (e.g. network). The system developed articulates in efficient manner the capabilities of the recently released WebGL standard, which makes available the accelerated graphic pipeline (formerly unusable). The dependency on specially customized hardware is eliminated, and yet efficient rendering rates are achieved. The Web increasingly competes against desktop applications in many scenarios, but the graphical demands of some of the applications (e.g. interactive scientific visualization by volume rendering), have impeded their successful settlement in Web scenarios. Performance, scalability, accuracy, security are some of the many challenges that must be solved before visual Web applications popularize. In this publication we discuss both performance and scalability of the volume rendering by WebGL ray-casting in two different but challenging application domains: medical imaging and radar meteorology.},
booktitle = {Proceedings of the 16th International Conference on 3D Web Technology},
pages = {137–146},
numpages = {10},
keywords = {weather radar volume, real-time visualization, ray casting, medical imaging, direct volume rendering, WebGL},
location = {Paris, France},
series = {Web3D '11}
}

@article{owens2007,
author = {Owens, John and Houston, Mike and Luebke, David and Green, Simon and Stone, John and Phillips, James},
year = {2008},
month = {05},
pages = {879-899},
title = {GPU computing},
volume = {96},
journal = {Proceedings of the IEEE},
doi = {10.1109/JPROC.2008.917757}
}

}
@article{cudabarnes,
author = {Burtscher, Martin and Pingali, Keshav},
year = {2011},
month = {12},
pages = {},
title = {An Efficient CUDA Implementation of the Tree-Based Barnes Hut n-Body Algorithm},
isbn = {9780123849885},
journal = {GPU Computing Gems Emerald Edition},
doi = {10.1016/B978-0-12-384988-5.00006-1}
}

@article{freelunchover,
  added-at = {2008-09-03T09:42:11.000+0200},
  author = {Sutter, Herb},
  biburl = {https://www.bibsonomy.org/bibtex/2215f355123504f02d0ddb1b40292abeb/gron},
  interhash = {1540da30b9424bf778012a96f1192730},
  intrahash = {215f355123504f02d0ddb1b40292abeb},
  journal = {Dr. Dobb’s Journal},
  keywords = {Concurrency PhD Proposal},
  number = 3,
  pages = {202--210},
  timestamp = {2008-09-03T09:42:12.000+0200},
  title = {The Free Lunch Is Over: A Fundamental Turn Toward Concurrency in Software},
  url = {http://www.gotw.ca/publications/concurrency-ddj.htm},
  volume = 30,
  year = 2005
}

  @book{galacticdynamics2nded,
 ISBN = {9780691130262},
 URL = {http://www.jstor.org/stable/j.ctvc778ff},
 abstract = {Since it was first published in 1987, Galactic Dynamics has become the most widely used advanced textbook on the structure and dynamics of galaxies and one of the most cited references in astrophysics. Now, in this extensively revised and updated edition, James Binney and Scott Tremaine describe the dramatic recent advances in this subject, makingGalactic Dynamics the most authoritative introduction to galactic astrophysics available to advanced undergraduate students, graduate students, and researchers.Every part of the book has been thoroughly overhauled, and many sections have been completely rewritten. Many new topics are covered, including N-body simulation methods, black holes in stellar systems, linear stability and response theory, and galaxy formation in the cosmological context. Binney and Tremaine, two of the world's leading astrophysicists, use the tools of theoretical physics to describe how galaxies and other stellar systems work, succinctly and lucidly explaining theoretical principles and their applications to observational phenomena. They provide readers with an understanding of stellar dynamics at the level needed to reach the frontiers of the subject.This new edition of the classic text is the definitive introduction to the field.?    A complete revision and update of one of the most cited references in astrophysics    Provides a comprehensive description of the dynamical structure and evolution of galaxies and other stellar systems    Serves as both a graduate textbook and a resource for researchers    Includes 20 color illustrations, 205 figures, and more than 200 problems    Covers the gravitational N-body problem, hierarchical galaxy formation, galaxy mergers, dark matter, spiral structure, numerical simulations, orbits and chaos, equilibrium and stability of stellar systems, evolution of binary stars and star clusters, and much more    Companion volume to Galactic Astronomy, the definitive book on the phenomenology of galaxies and star clusters    },
 author = {James Binney and Scott Tremaine},
 edition = {REV - Revised, 2},
 publisher = {Princeton University Press},
 title = {Galactic Dynamics: Second Edition},
 urldate = {2026-01-25},
 year = {2008}
} w




  @article{surveyofcomputation,
author = {Owens, John D. and Luebke, David and Govindaraju, Naga and Harris, Mark and Krüger, Jens and Lefohn, Aaron E. and Purcell, Timothy J.},
title = {A Survey of General-Purpose Computation on Graphics Hardware},
journal = {Computer Graphics Forum},
volume = {26},
number = {1},
pages = {80-113},
keywords = {GPGPU, general-purpose computing on graphics hardware, parallel computing, GPU, graphics hardware, SIMD, stream processing, stream computing, data-parallel computing, high-performance computing, HPC, I.3.1 Computer Graphics: Hardware architecture, I.3.6 Computer Graphics: Methodology and techniques, D.2.2 Software Engineering: Design tools and techniques},
doi = {https://doi.org/10.1111/j.1467-8659.2007.01012.x},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8659.2007.01012.x},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-8659.2007.01012.x},
abstract = {Abstract The rapid increase in the performance of graphics hardware, coupled with recent improvements in its programmability, have made graphics hardware a compelling platform for computationally demanding tasks in a wide variety of application domains. In this report, we describe, summarize, and analyze the latest research in mapping general-purpose computation to graphics hardware. We begin with the technical motivations that underlie general-purpose computation on graphics processors (GPGPU) and describe the hardware and software developments that have led to the recent interest in this field. We then aim the main body of this report at two separate audiences. First, we describe the techniques used in mapping general-purpose computation to graphics hardware. We believe these techniques will be generally useful for researchers who plan to develop the next generation of GPGPU algorithms and techniques. Second, we survey and categorize the latest developments in general-purpose application development on graphics hardware.},
year = {2007}
}

